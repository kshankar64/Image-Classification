# -*- coding: utf-8 -*-
"""ResNet Exercise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1py33uIv5h-R-7mD3Ay-GrNrEwdsN5zJU

# Reference Code

This code is taken from this blog: https://vitalflux.com/pytorch-load-predict-pretrained-resnet-model/
"""

from torchvision import models
dir(models)

# For Part C, you need to change this and load another ResNet Model
resnet = models.resnet50 (pretrained = True)

# Print Model architecture
resnet

# download a image in sample_data folder
# For part B, you need save 20 images in this folder for inference.
!mkdir sample_data/images/
!wget https://t2.ea.ltmcdn.com/en/razas/0/0/1/labrador-retriever_100_0_orig.jpg -P sample_data/images/

# load the image
from PIL import Image
img_dog = Image.open ('sample_data/images/labrador-retriever_100_0_orig.jpg').convert ('RGB')

# Display images
img_dog

# What's the image size??
img_dog.size

# imports for Image transformations
from torchvision import transforms

preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(
          mean=[0.485, 0.456, 0.406],
          std=[0.229, 0.224, 0.225])
    ])
img_dog_processed = preprocess (img_dog)

img_dog_processed.shape

import matplotlib.pyplot as plt
plt.imshow(  img_dog_processed.permute(1, 2, 0)  )

#
# Reshape, crop, and normalize the input tensor for feeding into network for evaluation
#
import torch
batch_img_dog_tensor = torch.unsqueeze(img_dog_processed, 0)

# shape of input
batch_img_dog_tensor.shape

# Change to evaluation mode from training mode
resnet.eval ()

# Prediction
out = resnet(batch_img_dog_tensor)

# What prediction looks like??
out

# Shape of prediction
out.shape

out[0][200:210]

# Finding the maximum index
torch.max(out, 1)

# Download the index to class name mapping
!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

"""Changes for Part A"""

# For Part A, you need to select 10 classes from this list
with open('imagenet_classes.txt') as f:
    labels = [line.strip() for line in f.readlines()]

labels[456]

#
# Find the index (tensor) corresponding to the maximum score in the out tensor.
# Torch.max function can be used to find the information
#
_, index = torch.max(out, 1)
#
# Find the score in terms of percentage by using torch.nn.functional.softmax function
# which normalizes the output to range [0,1] and multiplying by 100
#
percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100
#
# Print the name along with score of the object identified by the model
#
print(labels[index[0]], percentage[index[0]].item())
#
# Print the top 5 scores along with the image label. Sort function is invoked on the torch to sort the scores.
#
_, indices = torch.sort(out, descending=True)
[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]

percentage[200:210]

"""# Homework 2

Changes for Part A
"""

import os

path = "sample_data/images/"

list = []

# dirs=directories
for (root, dirs, file) in os.walk(path):
    for f in file:
        if '.jpg' in f:
            list.append(f)
list

def todisplay(img_path):
  image = Image.open(img_path).convert("RGB")
  image_tensor = transform(image )

  plt.subplot(1, 2, 1)
  plt.imshow(image)
  plt.title("Original Image")
  plt.axis('off')

  plt.subplot(1, 2, 2)
  plt.imshow(image_tensor.permute(1, 2, 0))
  plt.title("Transformed Image")
  plt.axis('off')

  plt.show()

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

model_parta = models.resnet50(pretrained=True) # declare your model here

# code to display 20 images, transformed images, their prediction index, class, and confidence score
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def prediction_image(image_path):
    image = Image.open(image_path)
    image_tensor = transform(image).unsqueeze(0)
    model_parta.eval()
    with torch.no_grad():
        output = model_parta(image_tensor)
    _, prediction = output.max(1)
    confidence = torch.nn.functional.softmax(output[0], dim=0).data.tolist()
    return prediction.item(), confidence


path = "sample_data/images/"
for i in list:
  img_path = path+ i
  prediction, confidence = prediction_image(img_path)
  todisplay(img_path)
  print("Resnet50 :")
  print("prediction ID:", prediction)
  print("prediction label:", labels[prediction])
  print("Confidence Score:", confidence[prediction])

  print("\n")

"""Changes for Part B"""

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

model_partb = models.resnet18(pretrained=True) # declare your model here

# code to display 20 images, transformed images, their prediction index, class, and confidence score
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def prediction_image(image_path):
    image = Image.open(image_path)
    image_tensor = transform(image).unsqueeze(0)
    model_partb.eval()
    with torch.no_grad():
        output = model_partb(image_tensor)
    _, prediction = output.max(1)
    confidence = torch.nn.functional.softmax(output[0], dim=0).data.tolist()
    return prediction.item(), confidence


path = "sample_data/images/"
for i in list:
  img_path = path+ i
  prediction, confidence = prediction_image(img_path)
  todisplay(img_path)
  print("Resnet18 :")
  print("prediction ID:", prediction)
  print("prediction label:", labels[prediction])
  print("Confidence Score:", confidence[prediction])
  print("\n")

"""Changes for Part C"""

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

model_partc = models.resnet152(pretrained=True) # declare your model here

# code to display 20 images, transformed images, their prediction index, class, and confidence score
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def prediction_image(image_path):
    image = Image.open(image_path)
    image_tensor = transform(image).unsqueeze(0)
    model_partc.eval()
    with torch.no_grad():
        output = model_partc(image_tensor)
    _, prediction = output.max(1)
    confidence = torch.nn.functional.softmax(output[0], dim=0).data.tolist()
    return prediction.item(), confidence



path = "sample_data/images/"
for i in list:
  img_path = path+ i
  prediction, confidence = prediction_image(img_path)
  todisplay(img_path)
  print("Resnet152 :")
  print("prediction ID:", prediction)
  print("prediction label:", labels[prediction])
  print("Confidence Score:", confidence[prediction])
  print("\n")

# Display comparison between results from parta, partb and partc.
